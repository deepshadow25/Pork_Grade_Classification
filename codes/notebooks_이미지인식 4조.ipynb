{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "toc-showmarkdowntxt": true,
    "toc-autonumbering": false
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# 개요",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "도축된 돼지고기의 이미지를 통해 등급을 분류하는 최적의 모델을 찾는다. \n\n## 4조\n* 멤버 : 김재현, 박영준, 양성주, 이성연\n* 발표자 : 박영준, 양성주, 이성연 중 1명\n* 이미지인식 발표자를 제외한 2명 중 1명이 객체인식 프로젝트 발표.\n\n## 진행 순서\n\n1. 데이터 수집\n(AIHub \"축산물 품질(QC) 이미지\" 데이터 : \nhttps://www.aihub.or.kr/aihubdata/data/view.do?currMenu=116&topMenu=100&aihubDataSe=ty&dataSetSn=158)\n\n2. 전처리 (및 증강)\n\n3. 모델링 (CNN 모델 적용)\n* epoch 변경 비교\n* 데이터 증강 정도에 따른 비교\n* 데이터셋 크기에 따른 비교\n\n4. 결과 분석 및 정리\n* 결과를 Complex Matrix로 제시(1+, 1, 2 Label)\n* log-loss (cross-entropy) 그래프 제시\n* 평가지표 그래프 제시 (Accuracy or ROC curve)\n* 어려웠던 점, 개선사항 제시\n\n5. ppt 작성, 발표 스크립트 작성 후 발표\n\n## 타임테이블\n\nhttps://timetreeapp.com/calendars/1WSUtkW3Qkui\n\n(timetree 계정 필요)\n\n## 레이블\n* 1+\n* 1\n* 2\n\n## 사용한 딥러닝 모델\n* net\n* net2\n* net3\n\n## 발표자료\n(구글드라이브 ppt 임시링크)\nhttps://docs.google.com/presentation/d/126VcopHBKpKRNaQCBY-UwmkzMiULGGFi/edit#slide=id.p6\n\n사용한 글꼴 : \n\n## 참고문헌\n* 한준희, 정성훈, 박경수 and 유태선. (2021). 딥러닝 이미지 인식 기술을 활용한 소고기 등심 세부 부위 분류. 한국산업경영시스템학회지, 44(3), 1-9.\n\n* https://www.nongmin.com/news/NEWS/ECO/COW/336724/view",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 데이터 준비",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Library, Module import",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pip install split-folders",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import splitfolders\n\nimport os\n\nimport cv2\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\nimport matplotlib.cm as cm\n\nimport tensorflow as tf\n\nimport pickle",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\nfrom tensorflow.keras import datasets, layers, models\n\nfrom tensorflow.keras.layers import Dense, Flatten, MaxPooling2D\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Dropout, BatchNormalization\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## 데이터 마운트 \n(용량 조절 / 구글드라이브에 있는 자료 접근)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from google.colab import drive\ndrive.mount('/content/drive')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import sys\nfrom PIL import Image\n\ndef change_img_qualty(original_path, change_path, qualty=85):\n    \"\"\"\n    Change Image Qualty\n    :param original_path: 원본 경로\n    :param change_path: 변경 후 새롭게 저장될 경로\n    :param qualty: Qualty(품질) 퍼센트(기본 : 85%)\n    :return:\n    \"\"\"\n    if not os.path.exists(change_path):\n        os.mkdir(change_path)\n    try:\n        ims_list = os.listdir(original_path)\n        ims_list.sort()\n    except FileNotFoundError as e:\n        print(\"이미지 원본 디렉터리가 존재하지 않습니다...\")\n        sys.exit(0)\n    success_cnt = 0\n    fail_cnt = 0\n    for filename in ims_list:\n        file = original_path + filename\n        try:\n            im = Image.open(file)\n            im.save(os.path.join(change_path, filename), qualty=qualty)\n            print(\"+ 성공 : {success}\\n  \"\n                  \"- {success_path}\"\n                  .format(success=file, success_path=os.path.join(change_path, filename))\n                  )\n            success_cnt += 1\n        except Exception as e:\n            print(\"+ 실패 : {fail}\".format(fail=file))\n            fail_cnt += 1\n    print(\"\\n성공 : {success_cnt} 건 / 실패 : {fail_cnt} 건\".format(success_cnt=success_cnt, fail_cnt=fail_cnt))\n    sys.exit(0)\n\n\nif __name__ == '__main__':\n    original_path = '/Desktop/tmp/0/'\n    change_path = '/Desktop/tmp/1/'\n    change_img_qualty(original_path, change_path)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "folder_path = '/content/drive/MyDrive/imageRec_data/Training'\nlabel_names = os.listdir(folder_path)\nlabel_names",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Train 데이터 불러오기 ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "path = '/content/drive/MyDrive/imageRec_data'\n\n# 서브 디렉토리 목록 출력\nfor root, subdirs, files in os.walk(path):\n    for d in subdirs:\n        fullpath = root + '/' + d\n        print(fullpath)\n\n# 서브 디렉토리별 파일 개수 출력\nfor root, subdirs, files in os.walk(path):\n    if len(files) > 0:\n        print(root, len(files))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "dataset = {}\n\n# 이미지와 라벨 리스트에 담기 (하나의 변수(자료구조)에 모든 이미지 담기)\nfor label in os.listdir(folder_path):\n    sub_path = folder_path+'/'+label+'/'\n    dataset[label] = []         # 라벨 키값 부여, 밸류값 빈리스트\n    for filename in os.listdir(sub_path):\n        dataset[label].append(sub_path+filename)    # 라벨 밸류값 넣기\n\ndataset",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# 이미지 전처리",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## resize with padding",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!mkdir resized",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!mkdir resized/Pig_seg_1+\n!mkdir resized/Pig_seg_1\n!mkdir resized/Pig_seg_2",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import time\ndataset.items()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "for label, filenames in dataset.items():\n    for filename in filenames:\n        img = cv2.imread(filename)\n\n        percent = 1\n        if(img.shape[1] > img.shape[0]) :       \n            percent = 128/img.shape[1]\n        else :\n            percent = 128/img.shape[0]\n\n        img = cv2.resize(img, dsize=(0, 0), fx=percent, fy=percent, interpolation=cv2.INTER_LINEAR)\n        y,x,h,w = (0,0,img.shape[0], img.shape[1])\n\n        w_x = (128-(w-x))/2  \n        h_y = (128-(h-y))/2\n\n        if(w_x < 0):         \n            w_x = 0\n        elif(h_y < 0):\n            h_y = 0\n\n        M = np.float32([[1,0,w_x], [0,1,h_y]])  \n        img_re = cv2.warpAffine(img, M, (128, 128))   \n\n        time.sleep(0.35)\n       \n        # cv2.imwrite('{0}.jpg',image .format(file)) #파일저장\n        cv2.imwrite('/content/resized/{0}/{1}'.format(label, filename.split(\"/\")[-1]) , img_re)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "path = '/content/resized'\n\n# 서브 디렉토리 목록 출력\nfor root, subdirs, files in os.walk(path):\n    for d in subdirs:\n        fullpath = root + '/' + d\n        print(fullpath)\n\n# 서브 디렉토리별 파일 개수 출력\nfor root, subdirs, files in os.walk(path):\n    if len(files) > 0:\n        print(root, len(files))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Data Split",
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": "splitfolders.ratio('resized', output='dataset', seed=77, ratio=(0.7, 0.15, 0.15))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Trainset Augmentation (선택사항)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "datagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n)\n# 회전각도(degree), 너비/높이 전환비율, 사다리꼴, 줌, 뒤집기\n# cutmix, mixup 등은 다른 함수(generator)를 사용해야 함.\n# 파일명은 기존에 없는 이름으로 부여",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "folder_path",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "for label in  os.listdir(folder_path):\n    label_path = folder_path + '/' + label + '/'\n    for filename in os.listdir(label_path): \n        filepath = label_path + filename\n\n        img = load_img(filepath)\n        # img 출력\n        # plt.imshow(img)\n        # break\n        x = img_to_array(img)\n        # x.shape 출력\n        # print(x.shape)\n        # break\n        x = x.reshape((1,) + x.shape)\n        # 데이터 묶음 개수(1,) : 데이터가 하나여도 (1,) + ...\n\n        i = 0\n        # flow : augmentation 함수 (결과를 실제로 output해줌 - 폴더에 이미지가 추가되는 것 확인)\n            # 용량이 커지므로 flow함수는 잘 쓰지는 않음... 다만 예시를 보기 좋다.\n            # generator (for문 안에서:generator 함수를 먼저 실행 후 종속코드 실행)\n            # flow 3번(증강 3번)\n        for batch in datagen.flow(x, batch_size=1,\n                                save_to_dir=label_path, save_prefix=label, save_format='jpg'):\n            i += 1\n            if i > 2:\n                break  ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## 전처리된 데이터 딕셔너리/리스트에 저장하기\n\nfolder_path = '/content/dataset/train'\ndataset = {}\n\n# 이미지와 라벨 리스트에 담기\nfor label in os.listdir(folder_path):\n    sub_path = folder_path+'/'+label+'/'\n    dataset[label] = []\n    for filename in os.listdir(sub_path):\n        dataset[label].append(sub_path+filename)\n\ndataset",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "label2index = {'Pig_seg_1+' : 0, 'Pig_seg_1' : 1 , 'Pig_seg_2' : 2}\n#labels = list(label2index.keys())\n#labels",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_train, y_train = [], []\n\nfor label, filenames in dataset.items():\n    for filename in filenames:\n        image = cv2.imread(filename) # img를 array 형태로 변경\n        \n        x_train.append(image)\n        y_train.append(label2index[label]) # label을 index로 변경\n        time.sleep(0.4)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_train, y_train = np.array(x_train), np.array(y_train)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_train = x_train.astype('int8')  \n# float32 : 메모리 용량이 너무 커짐(실수형)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_train.shape, y_train.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Zero Centering",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def zero_mean(image):\n    # zero-centering\n    return np.mean(image, axis=0)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "zero_mean_img = zero_mean(x_train)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "zero_mean_img.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_train -= zero_mean_img",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## 검증/시험 데이터 준비 및 pickle 파일 저장",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Test data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "folder_path = '/content/dataset/test'\ndataset = {}\n\n# 이미지와 라벨 리스트에 담기\nfor label in os.listdir(folder_path):\n    sub_path = folder_path+'/'+label+'/'\n    dataset[label] = []\n    for filename in os.listdir(sub_path):\n        dataset[label].append(sub_path+filename)\n\ndataset",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_test, y_test = [], []\n\nfor label, filenames in dataset.items():\n    for filename in filenames:\n        image = cv2.imread(filename) # img를 array 형태로 변경\n\n        x_test.append(image)\n        y_test.append(label2index[label]) # label을 index로 변경\n        time.sleep(0.4)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_test, y_test = np.array(x_test), np.array(y_test)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_test = x_test.astype('int8')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_test.shape, y_test.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_test -= zero_mean_img",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "path = '/content/dataset/test'\n\n# 서브 디렉토리 목록 출력\nfor root, subdirs, files in os.walk(path):\n    for d in subdirs:\n        fullpath = root + '/' + d\n        print(fullpath)\n\n# 서브 디렉토리별 파일 개수 출력\nfor root, subdirs, files in os.walk(path):\n    if len(files) > 0:\n        print(root, len(files))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Validation data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "folder_path = '/content/dataset/val'\ndataset = {}\n\n# 이미지와 라벨 리스트에 담기\nfor label in os.listdir(folder_path):\n    sub_path = folder_path+'/'+label+'/'\n    dataset[label] = []\n    for filename in os.listdir(sub_path):\n        dataset[label].append(sub_path+filename)\n\ndataset",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "dataset.items()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_val, y_val = [], []\n\nfor label, filenames in dataset.items():\n    for filename in filenames:\n        image = cv2.imread(filename) # img를 array 형태로 변경\n\n        x_val.append(image)\n        y_val.append(label2index[label]) # label을 index로 변경\n        time.sleep(0.4)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_val, y_val= np.array(x_val), np.array(y_val)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_val = x_val.astype('int8')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_val.shape, y_val.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_val -= zero_mean_img",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## 결과데이터 pickle로 저장하기",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "with open('x_train.pickle', 'wb') as f:\n    pickle.dump(x_train, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open('y_train.pickle', 'wb') as f:\n    pickle.dump(y_train, f, protocol=pickle.HIGHEST_PROTOCOL)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!mv x_train.pickle /content/drive/MyDrive/imageRec_data/pickle\n!mv y_train.pickle /content/drive/MyDrive/imageRec_data/pickle",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "with open('x_val.pickle', 'wb') as f:\n    pickle.dump(x_val, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open('y_val.pickle', 'wb') as f:\n    pickle.dump(y_val, f, protocol=pickle.HIGHEST_PROTOCOL)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!mv x_val.pickle /content/drive/MyDrive/imageRec_data/pickle\n!mv y_val.pickle /content/drive/MyDrive/imageRec_data/pickle",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "with open('x_test.pickle', 'wb') as f:\n    pickle.dump(x_test, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open('y_test.pickle', 'wb') as f:\n    pickle.dump(y_test, f, protocol=pickle.HIGHEST_PROTOCOL)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!mv x_test.pickle /content/drive/MyDrive/imageRec_data/pickle\n!mv y_test.pickle /content/drive/MyDrive/imageRec_data/pickle",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## pickle 파일 불러오기 \n(재사용)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\n!mv x_train.pickle /content\n!mv y_train.pickle /content\n!mv x_test.pickle /content\n!mv y_test.pickle /content\n!mv x_val.pickle /content\n!mv y_val.pickle /content\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "with open('x_train.pickle', 'rb') as x_train_pk:\n    pickle.load(x_train_pk)\n\nwith open('y_train.pickle', 'rb') as y_train_pk:\n    pickle.load(y_train_pk)\n\nwith open('x_val.pickle', 'rb') as x_val_pk:\n    pickle.load(x_val_pk)\n\nwith open('y_val.pickle', 'rb') as y_val_pk:\n    pickle.load(y_val_pk)\n\nwith open('x_test.pickle', 'rb') as x_test_pk:\n    pickle.load(x_test_pk)\n\nwith open('y_test.pickle', 'rb') as y_test_pk:\n    pickle.load(y_test_pk)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}